# 🔍 Ω 도구 & 지식 발견 메커니즘 (요약)

## 📋 빠른 이해

### 질문: "지식이나 도구는 어떻게 찾지?"

**답변**: 5가지 자동 발견 메커니즘이 동시에 작동합니다.

```
┌─────────────┬──────────────────┬──────────────────┬──────────────┐
│ 메커니즘    │ 빈도            │ 도구/지식       │ 현재 상태    │
├─────────────┼──────────────────┼──────────────────┼──────────────┤
│ 갭 분석     │ 매 사이클       │ 자동 도구 생성   │ ✅ 활발     │
│ 문제 기반   │ 실패 발생 시    │ 개선안 생성      │ ✅ 활발     │
│ 연구 파이프│ 2-3 사이클마다   │ 지식 문서        │ ✅ 활발     │
│ RL 랭킹     │ 5 사이클마다    │ 목표 자동 선택   │ ✅ 활발     │
│ 도구 조합   │ 필요 시          │ 새로운 능력      │ ⚠️ 수동     │
└─────────────┴──────────────────┴──────────────────┴──────────────┘

결과: 20개 도구 + 19개 지식 문서 + 43개 인사이트
```

---

## 1️⃣ 갭 분석 (Gap Analysis)

### 메커니즘

```
State 읽기 → 목표 vs 현재 도구 비교 → 부족한 것 찾기 → 도구 만들기
```

### 실제 사례

| 갭 | 찾은 사이클 | 해결책 | 결과 |
|------|----------|-------|------|
| "연구 자동화 없음" | 9 | `research_pipeline.py` 생성 | ✅ 웹 검색 자동화 |
| "영향 측정 불가" | 16 | `impact_analyzer.py` 생성 | ✅ ROE 계산 가능 |
| "중복 연구 방지 없음" | 17 | `novelty_checker.py` 생성 | ✅ 중복 제거 |

---

## 2️⃣ 문제 기반 발견 (Problem-Driven)

### 메커니즘

```
SWE-Bench 테스트 실패 → 원인 분석 → 도구 개선 → 재테스트
```

### 핵심 사례: Python 환경 설정 (Cycle 32)

```
❌ 문제: pytest-qt 부족
   (astropy, numpy 등 Python 프로젝트에서 테스트 의존성 누락)

✅ 해결책: discover_requirements() 함수 추가
   - requirements.txt 파싱
   - setup.py AST 분석
   - setup.cfg 읽기
   - 자동 설치: pip install -r test-requirements.txt

📈 결과:
   Before: 0/8 성공 (0%)
   After:  4/8 성공 (50%)
```

### 또 다른 사례: JavaScript npm (Cycle 57)

```
❌ 문제: npm 명령 실패
   (JavaScript 프로젝트에서 node_modules 부족)

✅ 해결책: swe_solver.py에 추가
   npm install --legacy-peer-deps
   npm install --force (폴백)

📈 예상 결과:
   Before: 0/11 성공 (0%)
   After:  3-5개 성공 (15-30%) 예상
```

---

## 3️⃣ 연구 파이프라인 (Research Pipeline)

### 메커니즘

```
WebSearch → 지식 문서 생성 → 인사이트 추출 → 도구 아이디어 → 구현
```

### 실제 흐름: 멀티-에이전트 조율 (Cycle 6-15)

```
질문: "LangGraph/CrewAI를 써야 할까?"

Cycle 6: 검색 1 - "agentic AI tools 2025"
→ 결과: LangGraph, CrewAI, AutoGen 등

Cycle 8: 검색 2 - "LangGraph 단점"
→ 결과: "고정된 DAG, 런타임 수정 불가"

Cycle 11: 검색 3 - "LangGraph GitHub issues"
→ 결과: Issue #4313 "동적 노드 추가 불가능"

Cycle 13: 합성
→ 결론: 외부 프레임워크는 자기진화 불가능
→ 결정: 내부 오케스트레이터 구축

Cycle 15-17: 도구 생성
→ tool_composer.py (도구 조합)
→ gap_analyzer.py (갭 식별)
→ novelty_checker.py (중복 제거)

결과:
  ✅ 5개 지식 문서 생성
  ✅ 3개 도구 생성
  ✅ 전략적 결정 (외부 거절, 내부 구축)
```

---

## 4️⃣ RL 랭킹 (Reinforcement Learning)

### 메커니즘

```
outcomes.log 점수 분석 → 카테고리별 평균 → 상위 선택 (80%) vs 탐색 (20%)
```

### 실제 데이터 (Cycle 55+)

```
ACTION SCORES (평균):
├─ web_research:        1.00 ⭐⭐⭐
├─ knowledge_synthesis: 0.95 ⭐⭐
├─ tool_creation:       0.92
├─ genome_mutation:     0.83
├─ token_reduction:     0.45 (낮음)

→ RL 선택: web_research 선택 (최고 점수)
→ 결과: 다음 5 사이클은 JavaScript npm 연구로 진행
→ 효과: 44% 벤치마크(322개 인스턴스) 새로 지원 가능
```

---

## 5️⃣ 도구 조합 (Tool Composition)

### 메커니즘

```
여러 도구를 파이프라인으로 연결 → 새로운 능력 출현
```

### 예시 (Cycle 21)

```
실행: python tool_composer.py full_cycle

Step 1: introspect.py
└─ 현재 상태 분석 (도구 20개, 지식 11개, 사이클 21)

Step 2: measure_gradient.py
└─ 진행도 측정 (지난 5 사이클 vs 기준)

Step 3: generate_goal.py
└─ 다음 목표 생성 (기울기 + RL 점수 + 현재 상태 기반)

결과: "SWE-Bench Lite 80/300" 목표 자동 선택
```

---

## 📊 현재 상태

### 도구 활용도

```
활발 사용 (>10회):
  ✅ web_search.py          164회   (주요: 연구)
  ✅ swe_solver.py           50회   (주요: SWE-Bench)
  ✅ research_pipeline.py    19회
  ✅ gap_analyzer.py         19회

중간 사용 (2-10회):
  ⚠️  generate_goal.py        8회
  ⚠️  measure_gradient.py     6회
  ⚠️  introspect.py           5회
  ⚠️  rl_goal_selector.py     4회

미사용 (0-1회):
  ❌ predict_errors.py        0회   (미통합)
  ❌ auto_repair.py           0회   (미통합)
  ❌ token_optimizer.py       1회   (한계)

활용률: 8/20 = 40% (개선 가능)
```

---

## 🎯 발견 조건

### 언제 어떤 메커니즘이 작동하나?

```
상황                           → 메커니즘           → 결과
──────────────────────────────────────────────────────────
목표는 있으나 도구 없음        → 갭 분석           → 새 도구
벤치마크 실패 패턴 발생        → 문제 기반         → 개선안
알 수 없는 영역 필요           → 연구 파이프라인   → 지식 문서
사용할 도구가 많음             → 도구 조합         → 새 능력
어떤 목표를 할지 모름          → RL 랭킹           → 자동 선택
구현하려는데 예시 없음         → 웹 검색           → 코드 샘플
너무 많은 시도 실패            → 탐색 증가         → 다양한 시도
좋은 결과 계속됨              → 탐색 감소         → 집중
```

---

## 💡 효과적인 메커니즘 Top 3

### 1위: 문제 기반 발견 (Problem-Driven)

**이유**:
- 명확한 목표 (SWE-Bench 점수)
- 즉시 측정 가능 (PASS/FAIL)
- 50% → 71% 개선 (Python)

**사용 비율**: 가장 높음 (지속적 개선)

---

### 2위: 연구 파이프라인 (Research Pipeline)

**이유**:
- 외부 데이터 수집 (실제 세상)
- 전략적 결정 지원 (외부 vs 내부)
- 5개 도구 자동 생성

**사용 비율**: 중간~높음 (주기적 사용)

---

### 3위: 갭 분석 (Gap Analysis)

**이유**:
- 자동화 가능 (매 사이클)
- 시스템적 (목표 → 갭 → 도구)
- 누락된 것을 찾음

**사용 비율**: 중간 (선택적)

---

## ⚠️ 개선 영역

### 미사용 도구 활성화

```
predict_errors.py (0회):
  문제: 생성됐으나 메인 루프에 미통합
  해결책: 자동 사전 체크로 매 사이클 실행

auto_repair.py (0회):
  문제: 오류 감지 후 자동 복구 필요
  해결책: predict_errors + auto_repair 파이프라인

token_optimizer.py (1회):
  문제: CLAUDE.md 이미 최적화됨
  해결책: 지식 문서 사후 압축
```

### 도구 활용률 목표

```
현재: 8/20 = 40%
목표: 16/20 = 80% (다음 10 사이클)

방법:
1. predict_errors → auto_repair 파이프라인 통합
2. 지식 문서에 대한 token_optimizer 자동 실행
3. tool_composer 루틴화 (매 5 사이클)
```

---

## 📈 다음 단계

### Cycle 60+에서 예상되는 발견

```
자동 시작 항목:
├─ JavaScript npm 검증 (문제 기반) - 진행 중
├─ Go 런타임 지원 (갭 분석) - 우선순위 낮음
├─ 예측 오류 통합 (도구 활용도) - 높음
└─ 지식 → 코드 자동화 (도구 조합) - 새로움

예상 결과:
├─ 도구: 22-25개 (현재 20)
├─ 지식: 22-25개 (현재 19)
└─ 활용률: 40% → 60% (개선)
```

---

## 🎯 핵심 통찰

**"Ω는 필요한 것을 발견하고, 만들고, 외부로 검증한다."**

```
발견 메커니즘 5개
    ↓
도구/지식 생성 (20 도구, 19 문서)
    ↓
outcomes.log 기록 (점수)
    ↓
RL 랭킹 (다음 우선순위)
    ↓
다음 사이클 (반복)
```

**핵심 특징**:
- ✅ 완전 자동 (사람 개입 없음)
- ✅ 외부 검증 (자기기만 방지)
- ✅ 측정 가능 (outcomes.log)
- ✅ 선택적 (RL로 우선순위 결정)
- ⚠️ 40% 도구 활용률 (개선 필요)

---

*Ω v0.8.1 - 외부 검증 기반 자기진화*

자세한 내용은 `DISCOVERY_MECHANISM.md` 참고
구체적 사례는 `DISCOVERY_FLOWCHART.md` 참고
