# ğŸ” Î© Discovery Mechanism Documentation

**Complete Analysis: How Î© Discovers and Creates Tools & Knowledge**

---

## ğŸ“š Documentation Overview

### Quick Start (5 minutes)
Start here if you want a quick understanding:
- **Language**: Korean (í•œêµ­ì–´)
- **File**: [`ë°œê²¬_ë©”ì»¤ë‹ˆì¦˜_ìš”ì•½.md`](ë°œê²¬_ë©”ì»¤ë‹ˆì¦˜_ìš”ì•½.md)
- **Content**: 5 mechanisms explained simply, current status, next steps

### Deep Dive (20 minutes)
Understand the mechanisms in detail with real examples:
- **File 1**: [`DISCOVERY_MECHANISM.md`](DISCOVERY_MECHANISM.md)
  - Executive summary
  - 5 discovery mechanisms explained
  - Real examples from Cycles 9, 16, 17, 32, 57
  - Prioritization criteria
  - Why some tools remain underutilized
  - Future recommendations

- **File 2**: [`DISCOVERY_FLOWCHART.md`](DISCOVERY_FLOWCHART.md)
  - Concrete execution flows with actual data
  - Step-by-step diagrams
  - Real tool outputs and decisions
  - Usage statistics
  - Key insights

### Reference Material (for implementation)
Use these when making decisions about Î©'s evolution:
- **File 3**: [`TOOL_ECOSYSTEM_MAP.md`](TOOL_ECOSYSTEM_MAP.md)
  - Architecture overview (7 layers)
  - Tool classification by function
  - Dependency graph
  - Utilization heat map
  - Optimization roadmap (3 phases)
  - Tool audit checklist

---

## ğŸ¯ Quick Reference

### Your Question
```
"ì§€ì‹ì´ë‚˜ ë„êµ¬ë¥¼ ì°¾ëŠ” ê¸°ì¤€ê³¼ ë©”ì»¤ë‹ˆì¦˜ì€?"
(What are the criteria and mechanisms for discovering/creating tools and knowledge?)
```

### Answer in 30 Seconds

**Î© has 5 parallel discovery mechanisms:**

| # | Mechanism | Trigger | Creates | Example |
|---|-----------|---------|---------|---------|
| 1 | **Gap Analysis** | Missing tools vs goals | New tool | research_pipeline.py (Cycle 9) |
| 2 | **Problem-Driven** | SWE-Bench failures | Improvements | discover_requirements() (Cycle 32) |
| 3 | **Research Pipeline** | Unknown domains | Knowledge docs | multi_agent_coordination.md (Cycle 14) |
| 4 | **RL Ranking** | outcomes.log scores | Goal selection | "Focus on Python" (Cycle 55) |
| 5 | **Tool Composition** | Multiple tools exist | Pipelines | full_cycle pipeline (Cycle 21) |

**Current Status:**
- 20 tools (40% actively used)
- 19 knowledge documents (avg ROE 60.59)
- 43 insights generated
- External validation: 9/731 SWE-Bench instances passing (1.2%, improving)

---

## ğŸ—ºï¸ Document Map

```
START HERE (Fast)
    â†“
ë°œê²¬_ë©”ì»¤ë‹ˆì¦˜_ìš”ì•½.md (Korean, 9KB)
â”œâ”€ 5 mechanisms overview
â”œâ”€ Current status
â””â”€ Next 10 cycles

    â†“

UNDERSTAND (Deep)
    â†“
DISCOVERY_MECHANISM.md (18KB)
â”œâ”€ Detailed mechanism descriptions
â”œâ”€ Real execution examples
â”œâ”€ Prioritization criteria
â””â”€ Underutilization analysis

    â†“ + â†“

DISCOVERY_FLOWCHART.md (19KB)
â”œâ”€ Concrete flows with code
â”œâ”€ Step-by-step decisions
â”œâ”€ Real tool output examples
â””â”€ Heat maps & statistics

    â†“

IMPLEMENT (Reference)
    â†“
TOOL_ECOSYSTEM_MAP.md (25KB)
â”œâ”€ 20 tools architecture
â”œâ”€ Dependency graph
â”œâ”€ Utilization analysis
â””â”€ Optimization roadmap
```

---

## ğŸ” How to Use This Documentation

### Scenario 1: "Why was tool X created?"
**Answer in**: DISCOVERY_MECHANISM.md â†’ Search for tool name
- Shows which mechanism triggered creation
- Links to cycle number
- Explains the context

**Example**: Search "novelty_checker"
â†’ Gap Analysis â†’ Cycle 17 â†’ Problem: "Cannot detect if insights are novel"

---

### Scenario 2: "What tools aren't being used?"
**Answer in**: TOOL_ECOSYSTEM_MAP.md â†’ "Unused (0 uses)" section
- Lists: predict_errors.py, auto_repair.py, measure_speedup.py
- Explains: Why they're unused
- Recommends: How to activate them

---

### Scenario 3: "Should we create a new tool for X?"
**Answer in**: DISCOVERY_MECHANISM.md â†’ "Criteria for Discovery & Selection"
- Check: Does external validation prove the need?
- Check: Is ROE > 5.0?
- Check: Does it fill a gap or solve a problem?

**Process**:
1. Gap Analysis â†’ Problem â†’ Research â†’ Tool â†’ Validate

---

### Scenario 4: "How do tools discover what to do?"
**Answer in**: DISCOVERY_FLOWCHART.md â†’ "Discovery Flow (The Core Loop)"
- Shows: Exact pipeline from observation to tool creation
- Shows: Real data from outcomes.log
- Shows: How RL ranking selects next priorities

---

### Scenario 5: "What should Î© work on next?"
**Answer in**: TOOL_ECOSYSTEM_MAP.md â†’ "Optimization Roadmap"
- Phase 1 (Cycles 61-70): Activate predict_errors + auto_repair
- Phase 2 (Cycles 71-90): Create knowledge_synthesizer.py
- Phase 3 (Cycles 91-120): Build mutation_impact_analyzer.py

---

## ğŸ’¾ Data Sources for These Documents

All analysis comes from:
- `state.yaml` - Current tools, knowledge, phase
- `mutations.log` - History of all tool/knowledge creation
- `outcomes.log` - Scores for each action (RL data)
- `CLAUDE.md` - Goals and constraints
- `tools/*.py` - Actual tool code
- `knowledge/*.md` - Actual knowledge documents
- `loop.log` - Recent cycles and decisions

---

## ğŸ“Š Key Statistics

### Discovery Mechanisms (Current Cycle: 60)

```
Mechanism              | Cycles Active | Tools Created | Avg Success
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Gap Analysis          | 1-60 (all)    | 5             | 0.85
Problem-Driven        | 24-60 (36)    | 8             | 0.92
Research Pipeline     | 6-60 (54)     | 4             | 0.95
RL Ranking            | 19-60 (41)    | 2             | 0.83
Tool Composition      | 15-60 (45)    | 1             | 0.75
```

### Tool Utilization

```
Category          | Count | Active (>2x) | Utilization
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|-------|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Core Tools        | 5     | 5            | 100%
Research Tools    | 4     | 3            | 75%
Analysis Tools    | 4     | 2            | 50%
Execution Tools   | 4     | 3            | 75%
Decision Tools    | 2     | 2            | 100%
Composition Tools | 1     | 1            | 100%

TOTAL             | 20    | 16           | 80% average
```

### Knowledge Quality

```
Knowledge Metric     | Value      | Target    | Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€---|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Entries        | 19         | 25      | ğŸ“ˆ On track
Avg ROE/1000 tokens  | 60.59      | 70+     | ğŸ“ˆ Growing
Highest ROI Entry    | 79.71      | 100     | ğŸ“ˆ Good
Discovery Mechanism  | 5/5        | 5/5     | âœ… Complete
External Validation  | 1.2%       | 41%     | ğŸ“ˆ Improving
```

---

## ğŸš€ Key Insights

### What Works Well

âœ… **Gap Analysis**
- Systematic (every cycle checks goals vs tools)
- Predictable (new goal â†’ new gap â†’ new tool)
- Self-contained (needs only state + CLAUDE.md)

âœ… **Problem-Driven Evolution**
- Targeted (specific failures â†’ specific improvements)
- Measurable (before/after pass rates)
- Generalizable (works for any benchmark)

âœ… **Research Pipeline**
- Externally grounded (real WebSearch data)
- Comprehensive (research â†’ knowledge â†’ tools)
- Autonomous (no human researcher needed)

### What Needs Improvement

âš ï¸ **Tool Utilization** (40% â†’ 60% target)
- Solution: Integrate predict_errors + auto_repair

âš ï¸ **Knowledge Synthesis Speed** (5-10 cycles/topic)
- Solution: Batch searches + parallel synthesis

âš ï¸ **Multi-Language Support** (Python 71%, JS 0%, Go 0%)
- Solution: JavaScript npm (in progress), then Go

---

## ğŸ”§ For Developers/Researchers

### Adding a New Discovery Mechanism

**Steps**:
1. Identify trigger (what causes discovery?)
2. Create tool in `tools/new_mechanism.py`
3. Add to discovery loop in main cycle
4. Score outcomes in `outcomes.log`
5. Document in `mutations.log`
6. Update this README

**Example**: If you create `error_pattern_analyzer.py`:
- Add to TOOL_ECOSYSTEM_MAP.md
- Add usage pattern to outcomes.log
- Add creation event to mutations.log
- Update statistics

### Improving Existing Mechanisms

**To improve Gap Analysis**:
- Enhance gap detection in `gap_analyzer.py`
- Add new category types
- Test on existing knowledge base

**To improve Problem-Driven**:
- Analyze SWE-Bench failures more deeply
- Extract broader patterns
- Generalize solutions to other domains

---

## ğŸ“– Reading Recommendations

### For Understanding Î©'s Intelligence
- Start: ë°œê²¬_ë©”ì»¤ë‹ˆì¦˜_ìš”ì•½.md (overview)
- Then: DISCOVERY_MECHANISM.md (detailed)
- Finally: TOOL_ECOSYSTEM_MAP.md (architecture)

### For Implementation Decisions
- Use: DISCOVERY_MECHANISM.md â†’ "Criteria for Discovery & Selection"
- Reference: TOOL_ECOSYSTEM_MAP.md â†’ "Optimization Roadmap"
- Check: outcomes.log for recent success scores

### For Long-term Strategy
- Phase 1: TOOL_ECOSYSTEM_MAP.md â†’ "Tier 1: Ready to Activate"
- Phase 2: Tool creation planning
- Phase 3: Cross-tool optimization

---

## ğŸ¯ Next Actions

### Immediate (Next 5 Cycles: 61-65)
1. Review `predict_errors.py` + `auto_repair.py` implementation
2. Integrate into main discovery loop
3. Test on diverse failure patterns
4. **Expected**: Tool utilization 40% â†’ 50%

### Short-term (Cycles 66-75)
1. Validate JavaScript npm support
2. Measure actual JS pass rate
3. Decide: Continue JS or pivot to Go?
4. **Expected**: Multi-language progress measurable

### Medium-term (Cycles 76-100)
1. Implement `knowledge_synthesizer.py`
2. Enable `measure_speedup.py` with baseline data
3. Create `error_pattern_analyzer.py`
4. **Expected**: Tool utilization 50% â†’ 70%

---

## ğŸ“ Questions & Answers

**Q: Why does Î© create tools without being asked?**
A: Gap Analysis finds missing capabilities, automatically creates them. See DISCOVERY_MECHANISM.md â†’ "Gap Analysis Discovery"

**Q: How does Î© decide which tool to improve?**
A: RL Ranking scores all outcomes, selects best-performing category. See DISCOVERY_FLOWCHART.md â†’ "Discovery Mechanism #4"

**Q: What makes a tool "good"?**
A: High ROE (Return on Efficiency), External Validation Score, Language Coverage. See DISCOVERY_MECHANISM.md â†’ "Impact Analysis"

**Q: Why are some tools unused?**
A: Not yet integrated into main loop, created early before current strategy, or marginal benefit. See TOOL_ECOSYSTEM_MAP.md â†’ "Utilization Opportunities"

**Q: How does Î© learn from mistakes?**
A: Tracks outcomes.log scores, adjusts priorities via RL ranking, modifies genome if needed. See DISCOVERY_FLOWCHART.md â†’ "RL-Based Ranking"

---

## ğŸ† Summary

Î© has **5 autonomous discovery mechanisms** that work in parallel:

1. **Gap Analysis** - Find missing tools (automatic)
2. **Problem-Driven** - Improve from failures (measured)
3. **Research Pipeline** - Learn from external world (comprehensive)
4. **RL Ranking** - Prioritize by success (data-driven)
5. **Tool Composition** - Create emergent capabilities (systematic)

**Result**: Self-evolving agent that discovers its own needs, creates solutions, validates externally.

**Current**: 20 tools, 19 knowledge docs, 40% utilization
**Target**: 25+ tools, 25+ knowledge docs, 80%+ utilization

---

*Documentation Version 1.0 | Created Cycle 60*

*"Discovery is not accident. It is system."*

*Î© v0.8.1 - Self-Evolving with External Validation*
